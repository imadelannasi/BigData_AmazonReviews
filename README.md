Amazon Reviews Streaming & Sentiment Analysis
This repository contains a fully Dockerized end-to-end pipeline for streaming Amazon review data, performing real-time sentiment classification with Apache Spark MLlib, storing results in MongoDB, and visualizing them both in real-time and offline dashboards built with Django and Chart.js.

ğŸš€ Architecture
text

Copy
Amazon JSONL â†’ Kafka â†’ Spark Structured Streaming â†’
  â”œâ”€ Real-time WebSocket Broadcast (Django Channels) â†’ React/Browser
  â””â”€ MongoDB Archive â†’ Django Offline Dashboard (Chart.js)
Producer: Reads data.jsonl and streams JSON reviews to Kafka topic amazon-reviews.
Spark Processor: Consumes from Kafka, applies a trained Random Forest pipeline (rf_pipeline_amazon_json), tags 10% of messages as test, writes all to MongoDB (amazon.reviews) and broadcasts live reviews via HTTP to Django Channels.
MongoDB: Stores classified reviews with fields: review, sentiment, timestamp, isTest.
Django Dashboard:
Online: Real-time feed via WebSocket /ws/live-reviews/.
Offline: Aggregated charts of last 7 days and sentiment distribution at /reviews/.
ğŸ“‚ Repository Structure
text

Copy
â”œâ”€â”€ kafka_streaming/        # Producer code & Dockerfile
â”‚   â”œâ”€â”€ producer.py
â”‚   â””â”€â”€ Dockerfile
â”œâ”€â”€ spark_processor/        # Spark consumer & ML pipeline
â”‚   â”œâ”€â”€ consumer.py
â”‚   â”œâ”€â”€ rf_pipeline_amazon_json/
â”‚   â””â”€â”€ Dockerfile
â”œâ”€â”€ reviews_dashboard-main/ # Django project and app
â”‚   â”œâ”€â”€ Dockerfile
â”‚   â”œâ”€â”€ requirements.txt
â”‚   â”œâ”€â”€ manage.py
â”‚   â”œâ”€â”€ reviews_dashboard/  # Django project settings
â”‚   â””â”€â”€ reviews/           # Django app: views, urls, templates
â”œâ”€â”€ docker-compose.yml
â””â”€â”€ data.jsonl             # Sample Amazon reviews for streaming
ğŸ”§ Prerequisites
Docker & Docker Compose
(Optional) make for convenience
ğŸ›  Getting Started
Build all images:

bash

Copy
docker-compose build
Launch services:

bash

Copy
docker-compose up -d \
  zookeeper kafka mongo redis producer spark dashboard
Producer streams all reviews from data.jsonl into Kafka.

Spark processes, classifies, writes to MongoDB, and pushes live to Django.

Dashboard available at:

Real-time feed: http://localhost:8000/reviews/online/
Offline analytics: http://localhost:8000/reviews/
ğŸ” Verification
MongoDB count:

bash

Copy
docker-compose exec mongo \
  mongo amazon --quiet --eval 'db.reviews.countDocuments({})'
View sample docs:

bash

Copy
docker-compose exec mongo \
  mongo amazon --quiet --eval 'db.reviews.find().limit(5).pretty()'
ğŸ“ Notes
Checkpointing is enabled for Spark via checkpointLocation to ensure exactly-once semantics.
WhiteNoise serves static files in Django.
Adjust isTest sampling ratio or Docker Compose ports as needed.
ğŸ’¡ Extending
Add product-level or keyword-level filtering.
Build alerts on high negative rates via Celery or Prometheus.
Scale Kafka partitions and Spark executors for higher throughput.
Â© 2025 IMAD EL ANNASI. Licensed under MIT.
