# Amazon Reviews Streaming & Sentiment Analysis

This repository contains a fully Dockerized end-to-end pipeline for streaming Amazon review data, performing real-time sentiment classification with Apache Spark MLlib, storing results in MongoDB, and visualizing them both in real-time and offline dashboards built with Django and Chart.js.

## ğŸš€ Architecture

text
Amazon JSONL â” Kafka â” Spark Structured Streaming â”
  â”œâ”€ Real-time WebSocket Broadcast (Django Channels) â” React/Browser
  â””â”€ MongoDB Archive â” Django Offline Dashboard (Chart.js)


* *Producer*: Reads data.jsonl and streams JSON reviews to Kafka topic amazon-reviews.
* *Spark Processor*: Consumes from Kafka, applies a trained Random Forest pipeline (rf_pipeline_amazon_json), tags 10% of messages as test, writes all to MongoDB (amazon.reviews) and broadcasts live reviews via HTTP to Django Channels.
* *MongoDB*: Stores classified reviews with fields: review, sentiment, timestamp, isTest.
* *Django Dashboard*:

  * *Online*: Real-time feed via WebSocket /ws/live-reviews/.
  * *Offline*: Aggregated charts of last 7 days and sentiment distribution at /reviews/.

## ğŸ“‚ Repository Structure


â”œâ”€â”€ kafka_streaming/      # Producer code & Dockerfile
â”‚   â”œâ”€â”€ producer.py
â”‚   â””â”€â”€ Dockerfile
â”œâ”€â”€ spark_processor/      # Spark consumer & ML pipeline
â”‚   â”œâ”€â”€ consumer.py
â”‚   â”œâ”€â”€ rf_pipeline_amazon_json/
â”‚   â””â”€â”€ Dockerfile
â”œâ”€â”€ reviews_dashboard-main/  # Django project and app
â”‚   â”œâ”€â”€ Dockerfile
â”‚   â”œâ”€â”€ requirements.txt
â”‚   â”œâ”€â”€ manage.py
â”‚   â”œâ”€â”€ reviews_dashboard/   # Django project settings
â”‚   â””â”€â”€ reviews/             # Django app: views, urls, templates
â”œâ”€â”€ docker-compose.yml
â””â”€â”€ data.jsonl             # Sample Amazon reviews for streaming


## ğŸ”§ Prerequisites

* Docker & Docker Compose
* (Optional) make for convenience

## ğŸ›  Getting Started

1. *Build all images*:

   bash
   docker-compose build
   

2. *Launch services*:

   bash
   docker-compose up -d \
     zookeeper kafka mongo redis producer spark dashboard
   

3. *Producer* streams all reviews from data.jsonl into Kafka.

4. *Spark* processes, classifies, writes to MongoDB and pushes live to Django.

5. *Dashboard* available at:

   * Real-time feed: http://localhost:8000/reviews/online/
   * Offline analytics: http://localhost:8000/reviews/

## ğŸ” Verification

* *MongoDB count*:

  bash
  docker-compose exec mongo \
    mongo amazon --quiet --eval 'db.reviews.countDocuments({})'
  
* *View sample docs*:

  bash
  docker-compose exec mongo \
    mongo amazon --quiet --eval 'db.reviews.find().limit(5).pretty()'
  

## ğŸ“ Notes

* Checkpointing is enabled for Spark via checkpointLocation to ensure exactly-once semantics.
* WhiteNoise serves static files in Django.
* Adjust isTest sampling ratio or Docker Compose ports as needed.

## ğŸ’¡ Extending

* Add product-level or keyword-level filtering.
* Build alerts on high negative rates via Celery or Prometheus.
* Scale Kafka partitions and Spark executors for higher throughput.

---

Â© 2025 Your Name. Licensed under MIT.")
